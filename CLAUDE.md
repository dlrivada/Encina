# Claude Code - Encina Guidelines

## Active Plans

> **IMPORTANT**: Before starting work, check for active plans in `docs/plans/`. Read the plan file to understand the current state and continue from where the last session left off.

| Plan | File | Status |
|------|------|--------|
| Test Consolidation | `docs/plans/test-consolidation-plan.md` | üü° In Progress |

## Project Philosophy

### Pre-1.0 Development Status

- **Current Phase**: Pre-1.0 - Initial Design & Architecture
- **No Backward Compatibility Required**: We are NOT maintaining backward compatibility
- **Breaking Changes**: Fully acceptable and encouraged if they improve the design
- **Migration Support**: NOT needed - no existing users to migrate
- **Final Name Change**: The library will be renamed in the last step (post-1.0)

### Design Principles

1. **Best Solution First**: Always choose the best technical solution, never compromise for compatibility
2. **Clean Architecture**: No legacy code, no deprecated features, no obsolete properties
3. **Pay-for-What-You-Use**: All features are opt-in, never forced on users
4. **Provider-Agnostic**: Use abstractions to support multiple implementations (EF Core, Dapper, ADO.NET)
5. **.NET 10 Only**: We use .NET 10 exclusively (very recent, stable release)

### Technology Stack

- **.NET Version**: .NET 10.0 (mandatory, no support for older versions)
- **Language Features**: Use latest C# features without hesitation
- **Breaking Changes**: Expected and acceptable in .NET 10 APIs
- **Nullable Reference Types**: Enabled everywhere

### Code Quality Standards

- **No Obsolete Attributes**: Never mark code as `[Obsolete]` for backward compatibility
- **No Legacy Code**: If we need to change something, we change it completely
- **No Migration Paths**: Don't implement migration helpers or compatibility layers
- **Clean Codebase**: Every line of code should serve a current purpose

### Architecture Decisions

#### Railway Oriented Programming (ROP)

- Core pattern: `Either<EncinaError, T>`
- Explicit error handling, no exceptions for business logic
- Validation returns `Either` with detailed errors

#### Messaging Patterns (All Optional)

1. **Outbox Pattern**: Reliable event publishing (at-least-once delivery)
2. **Inbox Pattern**: Idempotent message processing (exactly-once semantics)
3. **Saga Pattern**: Distributed transactions with compensation (orchestration-based)
4. **Scheduled Messages**: Delayed/recurring command execution
5. **Transactions**: Automatic database transaction management

#### Provider Coherence

- **Encina.Messaging**: Shared abstractions (IOutboxStore, IInboxStore, etc.)
- **Encina.EntityFrameworkCore**: EF Core implementation
- **Encina.Dapper**: Dapper implementation
- **Encina.ADO**: ADO.NET implementation
- Same interfaces, different implementations - easy to switch providers

#### Multi-Provider Implementation Rule (MANDATORY)

> **CRITICAL**: All provider-dependent features MUST be implemented for ALL 13 providers. This is a fundamental project rule, not just a testing requirement.

**The 13 Providers:**

| Category | Providers | Count |
|----------|-----------|-------|
| **ADO.NET** | Sqlite, SqlServer, PostgreSQL, MySQL | 4 |
| **Dapper** | Sqlite, SqlServer, PostgreSQL, MySQL | 4 |
| **EF Core** | Sqlite, SqlServer, PostgreSQL, MySQL | 4 |
| **MongoDB** | MongoDB | 1 |

> **Note**: Oracle was removed from pre-1.0 scope due to disproportionate maintenance cost. See [ADR-009](docs/architecture/adr/009-remove-oracle-provider-pre-1.0.md) for details. Oracle code is preserved in `.backup/oracle/` for potential future restoration.

**When this rule applies:**

- Implementing any store (OutboxStore, InboxStore, SagaStore, ScheduledMessageStore, etc.)
- Implementing repositories, Unit of Work, bulk operations
- Any feature that interacts with database-specific SQL or connection types
- Registering services in `ServiceCollectionExtensions`

**Provider-specific SQL differences to consider:**

| Provider | Parameters | LIMIT | Boolean | Notes |
|----------|------------|-------|---------|-------|
| SQLite | `@param` | `LIMIT @n` | `0/1` | String-based DateTime storage |
| SQL Server | `@param` | `TOP (@n)` | `bit` | Native DateTime, GUID |
| PostgreSQL | `@param` | `LIMIT @n` | `true/false` | Case-sensitive identifiers |
| MySQL | `@param` | `LIMIT @n` | `0/1` | Backtick identifiers |

**Excluded from this rule** (specialized providers with different purposes):

- Message brokers: RabbitMQ, Kafka, NATS, MQTT
- Caching: Redis, Memory
- Event sourcing: Marten

#### Specialized Provider Categories (Beyond the 13 Database Providers)

Beyond the 13 database providers, Encina has **specialized provider categories** that apply to specific feature areas. Each category has its own coherence rules.

##### 1. Caching Providers (8 providers)

| Provider | Type | Characteristics |
|----------|------|-----------------|
| **Encina.Caching.Memory** | L1 (In-Memory) | `IMemoryCache` wrapper, no distribution |
| **Encina.Caching.Hybrid** | L1+L2 (Multi-tier) | .NET 10 `HybridCache`, best of both |
| **Encina.Caching.Redis** | L2 (Distributed) | StackExchange.Redis, industry standard |
| **Encina.Caching.Valkey** | L2 (Distributed) | Open-source Redis fork (LF project) |
| **Encina.Caching.Dragonfly** | L2 (Distributed) | Redis-compatible, lower latency |
| **Encina.Caching.Garnet** | L2 (Distributed) | Microsoft's Redis alternative (C# native) |
| **Encina.Caching.KeyDB** | L2 (Distributed) | Redis-compatible, multi-threaded |
| **Encina.Caching.Memcached** | L2 (Distributed) | Simple protocol (planned) |

**When caching provider rules apply:**

- Implementing `ICacheProvider`
- Implementing `IPubSubProvider` (for backplane sync)
- Cache stampede protection, eager refresh, fail-safe patterns
- Tag-based invalidation, read/write-through patterns

**All 8 caching providers must support:**

- Get/Set/Remove operations
- TTL and expiration
- Serialization abstraction
- Pub/Sub for backplane (where applicable)

##### 2. Messaging Transport Providers (10 existing + 6 planned)

| Provider | Strategy | Best For |
|----------|----------|----------|
| **Encina.RabbitMQ** | Message Broker | Task distribution, work queues |
| **Encina.AzureServiceBus** | Message Broker | Azure-native, enterprise |
| **Encina.AmazonSQS** | Message Broker | AWS-native, serverless |
| **Encina.Kafka** | Event Streaming | Audit logs, event sourcing, replay |
| **Encina.NATS** | Pub/Sub + JetStream | Real-time, IoT, edge |
| **Encina.Redis.PubSub** | Pub/Sub | Real-time broadcasting |
| **Encina.MQTT** | Pub/Sub (IoT) | IoT devices, constrained networks |
| **Encina.InMemory** | Testing | Unit tests, development |
| **Encina.gRPC** | Request/Response | Service-to-service RPC |
| **Encina.GraphQL** | Query Language | API gateway, BFF |

**Planned transports (v0.15.0):**

- `Encina.GoogleCloudPubSub` - GCP coverage
- `Encina.AmazonEventBridge` - AWS EventBridge
- `Encina.Pulsar` - Apache Pulsar
- `Encina.Redis.Streams` - Redis Streams
- `Encina.ActiveMQ` - Apache ActiveMQ Artemis
- `Encina.Dapr` - Dapr abstraction layer

**When messaging transport rules apply:**

- Implementing `IMessageTransport`
- Outbox publishing to external brokers
- Inbox consumption from external sources
- Dead letter queue handling

**All messaging transports must support:**

- Send/Publish operations
- Subscription management
- Error handling and DLQ
- Message metadata propagation

##### 3. Distributed Lock Providers (4 existing + 8 planned)

| Provider | Backend | Mechanism |
|----------|---------|-----------|
| **Encina.DistributedLock.InMemory** | In-Memory | Single-process (testing) |
| **Encina.DistributedLock.Redis** | Redis | Redlock algorithm |
| **Encina.DistributedLock.SqlServer** | SQL Server | `sp_getapplock` |
| **Encina.DistributedLock.PostgreSQL** | PostgreSQL | `pg_advisory_lock` (planned) |
| **Encina.DistributedLock.MySQL** | MySQL | `GET_LOCK` (planned) |
| **Encina.DistributedLock.Azure** | Azure Blob | Blob leases (planned) |
| **Encina.DistributedLock.DynamoDB** | DynamoDB | Conditional writes (planned) |
| **Encina.DistributedLock.Consul** | Consul | Sessions (planned) |
| **Encina.DistributedLock.etcd** | etcd | Leases (planned) |
| **Encina.DistributedLock.ZooKeeper** | ZooKeeper | Ephemeral nodes (planned) |

**When distributed lock rules apply:**

- Implementing `IDistributedLockProvider`
- Leader election features
- Resource coordination patterns

**All lock providers must support:**

- TryAcquire with timeout
- Auto-release on timeout
- Cancellation token support

##### 4. Validation Providers (3 providers)

| Provider | Framework | Characteristics |
|----------|-----------|-----------------|
| **Encina.FluentValidation** | FluentValidation | Fluent API, complex rules, async |
| **Encina.DataAnnotations** | DataAnnotations | Attribute-based, built-in |
| **Encina.MiniValidator** | MiniValidator | Lightweight, zero-allocation |

**When validation provider rules apply:**

- Implementing `IValidationProvider`
- Registration via `ServiceCollectionExtensions`

**All validation providers must:**

- Integrate with `ValidationOrchestrator`
- Return `ValidationResult` with errors
- Support the same `ValidationPipelineBehavior`

##### 5. Scheduling Providers (2 + adapters)

| Provider | Backend | Characteristics |
|----------|---------|-----------------|
| **Encina.Messaging** (built-in) | Database | In-database scheduling, simple |
| **Encina.Hangfire** | Hangfire | Persistent jobs, dashboard |
| **Encina.Quartz** | Quartz.NET | Advanced triggers, clustering |

**When scheduling rules apply:**

- Implementing `IScheduledMessageStore`
- Scheduler backend adapters

##### 6. Event Sourcing Providers (1 primary)

| Provider | Backend | Characteristics |
|----------|---------|-----------------|
| **Encina.Marten** | PostgreSQL | Event store + document DB |
| **Encina.EventStoreDB** | EventStoreDB | Dedicated event store (future) |

**When event sourcing rules apply:**

- Implementing aggregate repositories
- Projection infrastructure
- Snapshot handling
- GDPR compliance (crypto-shredding)

##### 7. Cloud/Serverless Providers (3 providers)

| Provider | Platform | Triggers |
|----------|----------|----------|
| **Encina.AzureFunctions** | Azure Functions | HTTP, Queue, Timer, Durable |
| **Encina.AwsLambda** | AWS Lambda | HTTP, SQS, CloudWatch, API Gateway |
| **Encina.GoogleCloudFunctions** | GCP Functions | HTTP, Pub/Sub (planned) |

**Cloud provider triangle rule:**
When implementing cloud-specific features, consider AWS/Azure/GCP coverage.

##### 8. Resilience Providers (3 providers)

| Provider | Framework | Use Case |
|----------|-----------|----------|
| **Encina.Polly** | Polly | Circuit breaker, retry, bulkhead |
| **Encina.Extensions.Resilience** | Microsoft.Extensions.Resilience | .NET 10 native patterns |
| **Encina.Extensions.Http.Resilience** | Microsoft.Extensions.Http.Resilience | HTTP client resilience |

##### 9. Observability Providers (1 + exporters)

| Provider | Backend | Purpose |
|----------|---------|---------|
| **Encina.OpenTelemetry** | OpenTelemetry SDK | Tracing, metrics, instrumentation |
| **Encina.OpenTelemetry.AzureMonitor** | Azure Monitor | Azure exporter (planned) |
| **Encina.OpenTelemetry.AwsXRay** | AWS X-Ray | AWS exporter (planned) |
| **Encina.OpenTelemetry.Prometheus** | Prometheus | Metrics scraping (planned) |

##### 10. Testing Providers (12 packages)

| Provider | Purpose |
|----------|---------|
| **Encina.Testing** | Core test fixtures, fluent assertions |
| **Encina.Testing.Fakes** | Fake IEncina, stores, collectors |
| **Encina.Testing.Respawn** | Database reset between tests |
| **Encina.Testing.WireMock** | HTTP mocking |
| **Encina.Testing.Shouldly** | Shouldly assertions |
| **Encina.Testing.Verify** | Snapshot testing |
| **Encina.Testing.Bogus** | Fake data generation |
| **Encina.Testing.FsCheck** | Property-based testing |
| **Encina.Testing.Architecture** | ArchUnitNET rules |
| **Encina.Testing.Testcontainers** | Docker-based DB testing |
| **Encina.Testing.TUnit** | NativeAOT-compatible tests |
| **Encina.Testing.Pact** | Contract testing |

#### Provider Applicability Matrix

Use this matrix to determine which providers apply to each feature type:

| Feature Type | Database (13) | Caching (8) | Transport (10+) | Lock (4+) | Validation (3) |
|--------------|:-------------:|:-----------:|:---------------:|:---------:|:--------------:|
| **Outbox/Inbox/Saga** | ‚úÖ Required | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Scheduled Messages** | ‚úÖ Required | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Query Caching** | ‚ùå | ‚úÖ Required | ‚ùå | ‚ùå | ‚ùå |
| **Message Publishing** | ‚ùå | ‚ùå | ‚úÖ Required | ‚ùå | ‚ùå |
| **Resource Locking** | ‚ùå | ‚ùå | ‚ùå | ‚úÖ Required | ‚ùå |
| **Request Validation** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ Required |
| **Unit of Work** | ‚úÖ Required | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Multi-Tenancy** | ‚úÖ Required | ‚úÖ Where applicable | ‚úÖ Where applicable | ‚ùå | ‚ùå |
| **Audit Trail** | ‚úÖ Required | ‚ùå | ‚ùå | ‚ùå | ‚ùå |

#### When to Consider Each Provider Category

| Scenario | Providers to Consider |
|----------|----------------------|
| Implementing a messaging store feature | All 13 database providers |
| Adding a new cache pattern | All 8 caching providers |
| Creating a new transport-agnostic feature | All messaging transports |
| Adding cloud-specific feature | AWS + Azure + GCP (triangle) |
| Creating a validation pattern | All 3 validation providers |
| Adding distributed coordination | All distributed lock providers |

> **Rule of thumb**: If a feature touches provider-specific code, it must be implemented consistently across ALL providers in that category.

#### Opt-In Configuration

All messaging patterns are disabled by default:

```csharp
// Simple app - only what you need
config.UseTransactions = true;

// Complex distributed system - all patterns
config.UseTransactions = true;
config.UseOutbox = true;
config.UseInbox = true;
config.UseSagas = true;
config.UseScheduling = true;
```

#### Repository Pattern (Optional)

The repository pattern is **completely optional**. Most applications work fine using `DbContext` directly.

**When to use Repository:**

| Scenario | Recommendation |
|----------|----------------|
| Simple CRUD with EF Core | Use `DbContext` directly |
| Complex LINQ queries | Use `DbContext` directly |
| Single database, single DbContext | Use `DbContext` directly |
| Multiple DbContexts/databases | Consider Repository |
| Transactions with non-EF components | Consider Repository |
| Easy unit testing with mocks | Consider Repository |
| Switching providers (EF ‚Üí Dapper) | Consider Repository |
| DDD with aggregate repositories | Consider Repository |

**Philosophy**: The .NET community increasingly recognizes that repositories often add boilerplate without real benefit when using a mature ORM. `DbContext` is already a Unit of Work and `DbSet<T>` is already a repository. Encina provides the pattern for those who need it, but never forces it.

```csharp
// Most apps: Use DbContext directly with messaging patterns
services.AddDbContext<AppDbContext>(options => ...);
services.AddEncinaEntityFrameworkCore<AppDbContext>(config =>
{
    config.UseTransactions = true;
    config.UseOutbox = true;
});

// Only when needed: Opt-in to repository for specific entities
services.AddEncinaRepository<Order, OrderId>();
```

### Naming Conventions

#### Messaging Entities

- **Outbox**: `OutboxMessage` (not Message)
- **Inbox**: `InboxMessage` (not Message)
- **Saga**: `SagaState` (not Saga)
- **Scheduling**: `ScheduledMessage` (not ScheduledCommand)

#### Property Names (Standardized)

- **Type Information**: `RequestType` or `NotificationType` (not MessageType)
- **Error Information**: `ErrorMessage` (not Error - avoids CA1716 keyword conflict)
- **Timestamps**: Always UTC with `AtUtc` suffix
  - `CreatedAtUtc`, `ProcessedAtUtc`, `ScheduledAtUtc`, etc.
  - **Saga timestamps**: `StartedAtUtc`, `LastUpdatedAtUtc`, `CompletedAtUtc`
- **Retry Logic**: `RetryCount`, `NextRetryAtUtc` (not AttemptCount)
- **Identifiers**: Descriptive names (`SagaId` not `Id` when implementing interface)

#### Store Implementations

- Pattern: `{Pattern}Store{Provider}`
- Examples: `OutboxStoreEF`, `InboxStoreEF`, `SagaStoreEF`
- Never just `Store` or `Repository`

### Satellite Packages Philosophy

#### Coherence Across Providers

When implementing the same feature across different data access providers:

- **Same interfaces** (from Encina.Messaging)
- **Same configuration options** (from Encina.Messaging)
- **Different implementations** (provider-specific)
- **Easy migration** (change DI registration, rest stays the same)

Example:

```csharp
// Using EF Core
services.AddEncinaEntityFrameworkCore(config => {
    config.UseOutbox = true;
});

// Switch to Dapper (same interface, different implementation)
services.AddEncinaDapper(config => {
    config.UseOutbox = true; // Same configuration!
});
```

#### Validation Libraries Support

- Support multiple: FluentValidation, DataAnnotations, MiniValidator
- User chooses their preferred library
- Similar pattern for scheduling: Encina.Scheduling vs Hangfire/Quartz adapters

#### Validation Architecture (Orchestrator Pattern)

```
Encina (core)
‚îú‚îÄ‚îÄ Encina.Validation.IValidationProvider (interface)
‚îú‚îÄ‚îÄ Encina.Validation.ValidationOrchestrator (domain logic)
‚îú‚îÄ‚îÄ Encina.Validation.ValidationPipelineBehavior<,> (centralized behavior)
‚îú‚îÄ‚îÄ Encina.Validation.ValidationResult (immutable result)
‚îî‚îÄ‚îÄ Encina.Validation.ValidationError (record)

Encina.FluentValidation / DataAnnotations / MiniValidator
‚îú‚îÄ‚îÄ *ValidationProvider (implements IValidationProvider)
‚îî‚îÄ‚îÄ ServiceCollectionExtensions (registers orchestrator + provider)
```

Example:

```csharp
// All validation packages use the same pattern:
services.AddEncinaFluentValidation(typeof(MyValidator).Assembly);
// or
services.AddDataAnnotationsValidation();
// or
services.AddMiniValidation();

// Each registers:
// - IValidationProvider ‚Üí Provider-specific implementation
// - ValidationOrchestrator ‚Üí Centralized orchestration
// - ValidationPipelineBehavior<,> ‚Üí Generic behavior
```

### Testing Standards

Maintain high-quality test coverage that balances thoroughness with development velocity.

#### Coverage Targets

- **Line Coverage**: ‚â•85% (target for overall codebase)
- **Branch Coverage**: ‚â•80% (target for overall codebase)
- **Method Coverage**: ‚â•90% (target for overall codebase)
- **Mutation Score**: ‚â•80% (Stryker mutation testing)

#### Test Types - Apply Where Appropriate

Choose test types based on risk and value. Not every piece of code needs all test types:

1. **Unit Tests** ‚úÖ (Required for all code)
   - Test individual methods in isolation
   - Mock all dependencies
   - Fast execution (<1ms per test)
   - Location: `tests/{Package}.Tests/`

2. **Integration Tests** üü° (Critical paths, database operations)
   - Test against real databases (via Docker/Testcontainers)
   - Test full workflows end-to-end
   - Mark with: `[Trait("Category", "Integration")]`
   - Location: `tests/{Package}.IntegrationTests/`

3. **Contract Tests** üü° (Public APIs, interfaces)
   - Verify public API contracts don't break
   - Test interfaces, abstract classes
   - Location: `tests/{Package}.ContractTests/`

4. **Property-Based Tests** üü° (Complex logic, invariants)
   - Use FsCheck to generate random inputs
   - Verify invariants hold for varied inputs
   - Location: `tests/{Package}.PropertyTests/`

5. **Guard Clause Tests** üü° (Public methods with parameters)
   - Verify null checks throw `ArgumentNullException`
   - Use GuardClauses.xUnit library
   - Location: `tests/{Package}.GuardTests/`

6. **Load Tests** üü° (Performance-critical, concurrent code)
   - Stress test under high concurrency
   - Location: `tests/Encina.LoadTests/`

7. **Benchmarks** üü° (Hot paths, performance comparisons)
   - Measure actual performance with BenchmarkDotNet
   - Location: `tests/Encina.BenchmarkTests/`

#### Test Quality Standards

**Good tests should**:

- Have a clear, descriptive name (no `Test1`, `Test2`)
- Follow AAA pattern (Arrange, Act, Assert)
- Test ONE thing (single responsibility)
- Be independent (no shared state between tests)
- Be deterministic (same input = same output, always)
- Clean up resources (dispose, delete temp files, etc.)

**Avoid**:

- Skipping tests without justification
- Ignoring flaky tests (fix or delete them)
- Testing implementation details (test behavior, not internals)
- Using `Thread.Sleep` (prefer proper synchronization)
- Hard-coding paths, dates, GUIDs when avoidable

#### Docker Integration Testing

For database-dependent code, integration tests using Docker/Testcontainers are recommended.

**Quick Start:**

```bash
# Start essential services
docker compose --profile core up -d

# Start all databases
docker compose --profile databases up -d

# Start everything
docker compose --profile full up -d
```

> **Available Profiles**: `core`, `databases`, `messaging`, `caching`, `cloud`, `observability`, `full`
>
> See [Docker Infrastructure Guide](docs/infrastructure/docker-infrastructure.md) for complete details.

**Example test:**

```csharp
[Trait("Category", "Integration")]
[Trait("Database", "SqlServer")]
public class OutboxStoreSqlServerIntegrationTests : IAsyncLifetime
{
    private readonly TestDatabase _db;

    public OutboxStoreSqlServerIntegrationTests()
    {
        _db = new TestDatabase("Server=localhost,1433;...");
    }

    public async Task InitializeAsync()
    {
        await _db.CreateSchemaAsync();
    }

    public async Task DisposeAsync()
    {
        await _db.DropSchemaAsync();
    }

    [Fact]
    public async Task AddAsync_ShouldPersistMessage()
    {
        // Arrange
        var store = new OutboxStoreDapper(_db.Connection);
        var message = new OutboxMessage { ... };

        // Act
        await store.AddAsync(message);

        // Assert
        var retrieved = await store.GetMessageAsync(message.Id);
        Assert.NotNull(retrieved);
        Assert.Equal(message.Payload, retrieved.Payload);
    }
}
```

Run with:

```bash
dotnet run --file scripts/run-integration-tests.cs
```

#### Collection Fixtures (Container Reduction Strategy)

> **CRITICAL**: Integration tests use shared xUnit `[Collection]` fixtures to keep Docker containers low (~23 instead of ~71). **NEVER** create per-class fixtures for database tests.

**Rule**: Every integration test class MUST use `[Collection("Provider-Database")]` to share a single Docker container per provider/database combination.

**Existing collections** (defined in `Collections.cs` files):

| Collection | Fixture | Notes |
| ---------- | ------- | ----- |
| `ADO-SqlServer` | `SqlServerFixture` | |
| `ADO-PostgreSQL` | `PostgreSqlFixture` | |
| `ADO-MySQL` | `MySqlFixture` | |
| `ADO-Sqlite` | `SqliteFixture` | `DisableParallelization = true` |
| `Dapper-SqlServer` | `SqlServerFixture` | |
| `Dapper-PostgreSQL` | `PostgreSqlFixture` | |
| `Dapper-MySQL` | `MySqlFixture` | |
| `Dapper-Sqlite` | `SqliteFixture` | `DisableParallelization = true` |
| `EFCore-SqlServer` | `EFCoreSqlServerFixture` | |
| `EFCore-PostgreSQL` | `EFCorePostgreSqlFixture` | |
| `EFCore-MySQL` | `EFCoreMySqlFixture` | |
| `EFCore-Sqlite` | `EFCoreSqliteFixture` | `DisableParallelization = true` |

**New test class template:**

```csharp
[Collection("ADO-PostgreSQL")]  // REQUIRED - shares fixture across all classes
[Trait("Category", "Integration")]
[Trait("Database", "PostgreSQL")]
public class MyNewTests : IAsyncLifetime
{
    private readonly PostgreSqlFixture _fixture;

    public MyNewTests(PostgreSqlFixture fixture) => _fixture = fixture;

    public async Task InitializeAsync() => await _fixture.ClearAllDataAsync();
    public Task DisposeAsync() => Task.CompletedTask;
}
```

**Rules:**

1. ‚ùå NEVER use `IClassFixture<T>` for database fixtures - always use `[Collection]`
2. ‚ùå NEVER call `new SqlServerFixture()` or `_fixture = new()` - inject via constructor
3. ‚ùå NEVER call `_fixture.DisposeAsync()` from tests - the collection owns the lifecycle
4. ‚úÖ Use `_fixture.ClearAllDataAsync()` in `InitializeAsync()` for data cleanup
5. ‚úÖ Use `_fixture.CreateConnection()` for shared connections (but NEVER dispose them for SQLite)

**SQLite special rules** (shared in-memory DB):

- `CreateConnection()` returns the SAME shared connection object
- NEVER wrap it in `using`/`await using`
- NEVER pass it to wrappers that dispose (like `SchemaValidatingConnection`)
- When a disposable connection is needed, create: `new SqliteConnection(_fixture.ConnectionString)`

See [Integration Test Container Strategy](docs/testing/integration-tests.md#collection-fixture-strategy) for full details.

#### Test Organization

```
tests/
‚îú‚îÄ‚îÄ Encina.UnitTests/          # Consolidated unit tests (9,164 tests as of v0.12.0-dev, Feb 2026)
‚îÇ   ‚îú‚îÄ‚îÄ ADO/
‚îÇ   ‚îú‚îÄ‚îÄ AspNetCore/
‚îÇ   ‚îú‚îÄ‚îÄ Caching/
‚îÇ   ‚îú‚îÄ‚îÄ Core/
‚îÇ   ‚îú‚îÄ‚îÄ Dapper/
‚îÇ   ‚îú‚îÄ‚îÄ DomainModeling/
‚îÇ   ‚îú‚îÄ‚îÄ EntityFrameworkCore/
‚îÇ   ‚îú‚îÄ‚îÄ Messaging/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ Encina.IntegrationTests/   # Consolidated integration tests (2,251 tests)
‚îú‚îÄ‚îÄ Encina.PropertyTests/      # Property-based tests (352 tests)
‚îú‚îÄ‚îÄ Encina.ContractTests/      # Contract tests (247 tests)
‚îú‚îÄ‚îÄ Encina.GuardTests/         # Guard clause tests (1,037 tests)
‚îú‚îÄ‚îÄ Encina.LoadTests/          # Load testing harness
‚îú‚îÄ‚îÄ Encina.NBomber/            # NBomber scenarios
‚îú‚îÄ‚îÄ Encina.BenchmarkTests/     # BenchmarkDotNet benchmarks
‚îÇ   ‚îú‚îÄ‚îÄ Encina.Benchmarks/
‚îÇ   ‚îú‚îÄ‚îÄ Encina.AspNetCore.Benchmarks/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ Encina.TestInfrastructure/ # Shared test infrastructure
‚îî‚îÄ‚îÄ Encina.Testing.Examples/   # Reference examples
```

#### Test Coverage for All 13 Providers

Tests MUST cover ALL 13 providers as defined in the [Multi-Provider Implementation Rule](#multi-provider-implementation-rule-mandatory) section above.

> **Reminder**: The 13 providers are: ADO.NET (4), Dapper (4), EF Core (4), and MongoDB (1).

#### Test Type Guidelines by Feature Category

**IMPORTANT**: Not all test types can be justified with `.md` files. The decision depends on the feature category:

| Test Type | Database Features | Non-DB Features | Notes |
|-----------|-------------------|-----------------|-------|
| **UnitTests** | ‚úÖ Required | ‚úÖ Required | Always required |
| **GuardTests** | ‚úÖ Required | ‚úÖ Required | All public methods |
| **PropertyTests** | ‚úÖ Required | üü° If complex | Cross-provider invariants |
| **ContractTests** | ‚úÖ Required | üü° If public API | API consistency |
| **IntegrationTests** | ‚úÖ **Required** | üìÑ Justify if skip | DB features MUST have real tests |
| **LoadTests** | ‚ö†Ô∏è See below | üìÑ Justify if skip | Only for concurrent features |
| **BenchmarkTests** | üìÑ Justify if skip | üìÑ Justify if skip | Only for hot paths |

#### IntegrationTests for Database Features

**For database-related milestones (like v0.12.0 Database & Repository):**

- ‚ùå **DO NOT** create `.md` justification files for IntegrationTests
- ‚úÖ **DO** create real IntegrationTests using Docker/Testcontainers
- The whole point of database features is to interact with real databases

**Why real IntegrationTests are mandatory for DB features:**

1. SQL syntax varies by provider (Oracle uses `:param`, MySQL uses backticks)
2. Connection/transaction behavior differs between providers
3. Type mappings vary (GUID storage, DateTime precision, boolean representation)
4. We have Docker infrastructure (`docs/infrastructure/docker-infrastructure.md`)

#### LoadTests Guidelines

LoadTests are only meaningful for features with **concurrent behavior**:

| Feature | LoadTest? | Reason |
|---------|-----------|--------|
| Repository | üìÑ Justify | Thin wrapper, load is on DB |
| Specification | üìÑ Justify | SQL generation is CPU-bound, fast |
| **Unit of Work** | ‚úÖ Implement | Connection/transaction management under load |
| **Multi-Tenancy** | ‚úÖ Implement | Tenant isolation under concurrent access |
| **Read/Write Separation** | ‚úÖ Implement | Replica distribution is exactly what LoadTests validate |
| Module Isolation | üìÑ Justify | Only active in development mode |

#### BenchmarkTests Guidelines

BenchmarkTests are only meaningful for **hot paths** where microseconds matter:

| Feature | Benchmark? | Reason |
|---------|------------|--------|
| Repository | üìÑ Justify | Overhead is negligible vs DB |
| Specification | ‚ö†Ô∏è Maybe | Complex query generation might benefit |
| Unit of Work | üìÑ Justify | Transaction management, not a hot path |
| Multi-Tenancy | üìÑ Justify | Single WHERE clause, O(1) |
| **Read/Write Separation** | ‚úÖ Implement | Replica selection algorithms are benchmarkable |
| Module Isolation | üìÑ Justify | Development-only, disabled in production |

#### BenchmarkDotNet Guidelines

> **CRITICAL**: Follow these rules when creating or modifying benchmarks to avoid common pitfalls discovered during Issue #564.

**1. Use BenchmarkSwitcher, NOT BenchmarkRunner**

```csharp
// ‚ùå WRONG - BenchmarkRunner.Run<T>() IGNORES command-line arguments like --filter
BenchmarkRunner.Run<MyBenchmarks>(config);

// ‚úÖ CORRECT - BenchmarkSwitcher supports --filter, --list, --job, etc.
BenchmarkSwitcher.FromAssembly(typeof(Program).Assembly).Run(args, config);
```

**Why this matters**: Without `BenchmarkSwitcher`, you cannot filter benchmarks at runtime. Running 200+ benchmarks when you only need 10 wastes hours of time.

**2. Materialize IQueryable Results**

BenchmarkDotNet validates return values. Deferred execution (like `IQueryable<T>`) causes validation errors:

```csharp
// ‚ùå WRONG - Returns deferred execution, BenchmarkDotNet rejects it
public IQueryable<Entity> GetEntities()
{
    return _context.Entities.Where(e => e.IsActive);
}

// ‚úÖ CORRECT - Materialize with .ToList()
public List<Entity> GetEntities()
{
    return _context.Entities.Where(e => e.IsActive).ToList();
}
```

**Error you'll see**: "Benchmark returns a deferred execution result (IQueryable<T>). You need to either change the method declaration to return a materialized result or consume it on your own."

**3. Verify Filtering Before Full Execution**

Always verify your filter works before running the full benchmark suite:

```bash
# Step 1: List benchmarks that will run (fast)
dotnet run -c Release -- --list flat --filter "*EntityFrameworkCore*"

# Step 2: Only if list looks correct, run the actual benchmarks
dotnet run -c Release -- --filter "*EntityFrameworkCore*" --job short
```

**4. Test Entities Must Match Benchmark Operations**

Don't use `AddInclude()` on entities without navigation properties:

```csharp
// ‚ùå WRONG - BenchmarkEntity has no "Category" navigation property
public class StringIncludeSpec : QuerySpecification<BenchmarkEntity>
{
    public StringIncludeSpec()
    {
        AddInclude("Category"); // This will fail or produce NA results
    }
}

// ‚úÖ CORRECT - Only include existing navigation properties
public class StringIncludeSpec : QuerySpecification<Order>
{
    public StringIncludeSpec()
    {
        AddInclude("Customer"); // Customer exists as navigation property
    }
}
```

**5. Common BenchmarkDotNet Arguments**

| Argument | Purpose | Example |
|----------|---------|---------|
| `--list flat` | List matching benchmarks without running | `--list flat --filter "*Repo*"` |
| `--filter` | Run only matching benchmarks | `--filter "*EntityFrameworkCore*"` |
| `--job short` | Quick validation run (3 iterations) | `--job short` |
| `--job dry` | Validate setup without execution | `--job dry` |
| `--exporters` | Control output formats | `--exporters json markdown` |

**6. Benchmark Output Location**

All benchmark results go to `artifacts/performance/`:

```csharp
var config = DefaultConfig.Instance
    .WithArtifactsPath(Path.Combine(
        Directory.GetCurrentDirectory(),
        "..", "..", "..", "..", "..",
        "artifacts", "performance", "results"));
```

#### Test Justification Documents (.md)

When a test type is **legitimately** NOT implemented for a feature, create a justification document:

**Format**: `{TestProject}/{Provider/Feature}/{Feature}.md`

**When to use justification documents:**

- ‚úÖ BenchmarkTests for thin wrappers (Repository, Tenancy)
- ‚úÖ LoadTests for non-concurrent features (Repository, Specification)
- ‚ùå **NEVER** for IntegrationTests on database features
- ‚ùå **NEVER** for UnitTests, GuardTests, ContractTests

**Required content**:

```markdown
# {Test Type} - {Provider} {Feature}

## Status: Not Implemented

## Justification
[Technical reasons why this test type is not needed]

### 1. [Reason category]
[Detailed explanation]

### 2. Adequate Coverage from Other Test Types
- **Unit Tests**: [what's covered]
- **Guard Tests**: [what's covered]
- **Property Tests**: [what's covered]
- **Contract Tests**: [what's covered]

### N. Recommended Alternative
[How to test this if needed in the future]

## Related Files
- `src/...` - Source files
- `tests/...` - Existing test files

## Date: YYYY-MM-DD
## Issue: #NNN
```

**Rule**: If a folder has neither `.cs` test files nor `.md` justification, the test coverage for that feature/provider has NOT been evaluated yet.

#### Supported Test Types (Encina.{Type}Tests)

| Project | Purpose | When Required |
|---------|---------|---------------|
| `Encina.UnitTests` | Isolated unit tests | ‚úÖ Always required |
| `Encina.GuardTests` | Null/parameter validation | ‚úÖ All public methods |
| `Encina.PropertyTests` | Invariant verification | üü° Complex logic |
| `Encina.ContractTests` | API contract verification | üü° Public interfaces |
| `Encina.IntegrationTests` | Real database/external | üü° Database operations |
| `Encina.LoadTests` | Performance under load | üü° Critical paths |
| `Encina.BenchmarkTests` | Micro-benchmarks | üü° Hot paths |

**Coverage target**: ‚â•85% line coverage across all test types combined.

#### Testing Workflow

**Recommended approach for new features**:

1. Write unit tests covering the main functionality
2. Implement feature
3. Add additional test types based on risk/complexity:
   - Integration tests for database/external dependencies
   - Property tests for complex logic with invariants
   - Guard tests for public APIs
4. Verify tests pass

**Before committing**:

```bash
# Run all tests
dotnet test Encina.slnx --configuration Release

# Optional: Check coverage
dotnet test --collect "XPlat Code Coverage"

# Optional: Run mutation testing
dotnet run --file scripts/run-stryker.cs
```

**CI/CD enforces**:

- ‚úÖ All tests pass
- ‚úÖ 0 build warnings
- ‚úÖ Code formatting
- ‚úÖ Public API compatibility

#### Examples of Complete Test Coverage

**Example: OutboxStore**

```csharp
// 1. Unit Tests
OutboxStoreTests.cs
- AddAsync_ValidMessage_ShouldSucceed()
- GetPendingMessagesAsync_WithFilter_ShouldReturnFiltered()
- MarkAsProcessedAsync_ValidId_ShouldUpdateTimestamp()

// 2. Integration Tests (Docker)
OutboxStoreIntegrationTests.cs
- AddAsync_ShouldPersistToRealDatabase()
- GetPendingMessages_ShouldQueryRealDatabase()
- ConcurrentWrites_ShouldNotCorruptData()

// 3. Contract Tests
OutboxStoreContractTests.cs
- AllImplementations_MustFollowIOutboxStoreContract()
- AddAsync_AllProviders_MustReturnSameResult()

// 4. Property Tests
OutboxStorePropertyTests.cs
- AddThenGet_AlwaysReturnsWhatWasAdded()
- GetPending_NeverReturnsProcessedMessages()

// 5. Guard Tests
OutboxStoreGuardTests.cs
- AddAsync_NullMessage_ThrowsArgumentNullException()
- GetMessageAsync_EmptyGuid_ThrowsArgumentException()

// 6. Load Tests
OutboxStoreLoadTests.cs
- HighConcurrency_1000Writes_AllSucceed()
- BulkOperations_10000Messages_WithinTimeout()

// 7. Benchmarks
OutboxStoreBenchmarks.cs
- AddAsync_Baseline()
- GetPendingMessages_Batch100vs1000()
```

**Result**: Comprehensive coverage of critical functionality.

#### Test Data Management

Use builders for test data:

```csharp
public class OutboxMessageBuilder
{
    private Guid _id = Guid.NewGuid();
    private string _payload = "{}";
    private DateTime _createdAt = DateTime.UtcNow;

    public OutboxMessageBuilder WithId(Guid id)
    {
        _id = id;
        return this;
    }

    public OutboxMessageBuilder WithPayload(string payload)
    {
        _payload = payload;
        return this;
    }

    public OutboxMessage Build() => new()
    {
        Id = _id,
        Payload = _payload,
        CreatedAtUtc = _createdAt
    };
}

// Usage
var message = new OutboxMessageBuilder()
    .WithPayload("{\"test\":true}")
    .Build();
```

#### Test Output Conventions

**IMPORTANT**: All test outputs MUST go to the `artifacts/` directory, never to the repository root.

| Output Type | Location |
|-------------|----------|
| Test results | `artifacts/test-results/` |
| Code coverage | `artifacts/coverage/` |
| Benchmark results | `artifacts/performance/` |
| Load test metrics | `artifacts/load-metrics/` |
| Mutation reports | `artifacts/stryker/` |

**Forbidden root-level outputs** (these should NOT exist):

- `TestResults/` ‚ùå
- `test-results.log` ‚ùå
- `coverage-*` ‚ùå
- `BenchmarkDotNet.Artifacts/` ‚ùå

When configuring test projects or scripts:

- Use `--results-directory artifacts/test-results` for `dotnet test`
- Use `--output artifacts/coverage` for coverage collectors
- Configure `runsettings` files to use `artifacts/` paths
- Scripts should write to `artifacts/` subdirectories

#### Remember

> **Quality is important but should be balanced with development velocity.**
>
> Focus on testing what matters: critical paths, complex logic, and public APIs.
> Add tests incrementally as features mature.

### Code Analysis

- **Zero Warnings**: All CA warnings must be addressed (fix or suppress with justification)
- **Suppression Rules**:
  - CA1848 (LoggerMessage delegates): Suppress if performance optimization is future work
  - CA2263 (Generic overload): Suppress when dynamic serialization is needed
  - CA1716 (Keyword conflicts): Fix by renaming (e.g., `Error` ‚Üí `ErrorMessage`)

### .NET 10 / C# 14 Reference (Released November 2025)

> **Important**: .NET 10 is an LTS release supported through November 2028. This section documents key changes and new features since Claude's knowledge cutoff (January 2025).

#### C# 14 New Features

1. **Extension Members** (headline feature):
   - Extension properties, extension operators, and static extension members
   - Defined using `extension` block syntax
   - Can add instance methods, properties, indexers, operators to any type

2. **Field Keyword**:
   - Access auto-implemented property backing field directly: `field`
   - Use in custom get/set accessors without declaring backing field

3. **User-Defined Compound Assignment Operators**:
   - Can now override `+=`, `-=`, etc. explicitly for performance

4. **Other C# 14 Features**:
   - Null-conditional assignment
   - Partial constructors and events
   - File-based apps: run `*.cs` files directly with `dotnet run` (no .csproj needed)

#### .NET 10 Breaking Changes

| Change | Impact |
|--------|--------|
| `dotnet new sln` defaults to SLNX format | New solution format |
| `dotnet restore` audits transitive packages | Security audits enabled |
| OpenAPI 3.1 with breaking schema changes | `Nullable` removed from `OpenApiSchema`, use `JsonSchemaType.Null` |
| `WebHostBuilder`, `IWebHost` obsolete | Use minimal hosting APIs |
| `WithOpenApi` deprecated | Use new OpenAPI generator |
| Default images use Ubuntu | Container base image change |

#### PublicAPI Analyzers (RS0016/RS0017)

The `Microsoft.CodeAnalysis.PublicApiAnalyzers` package tracks public API changes via:

- `PublicAPI.Shipped.txt` - APIs in released versions
- `PublicAPI.Unshipped.txt` - APIs in current development

**Key rules**:

- RS0016: Symbol not in declared API (add to Unshipped.txt)
- RS0017: Symbol in declared API but not public/found (remove from txt)
- RS0036/RS0037: Nullable annotation mismatches

**Fixing RS0016/RS0017**:

1. Use Visual Studio code fix to add/remove entries
2. Manually edit `PublicAPI.Unshipped.txt`
3. Format: `Namespace.Type.Member(params) -> ReturnType`
4. Nullable annotations: `string!` (non-null), `string?` (nullable)

#### Official Documentation Links

- [What's new in .NET 10](https://learn.microsoft.com/en-us/dotnet/core/whats-new/dotnet-10/overview)
- [What's new in C# 14](https://learn.microsoft.com/en-us/dotnet/csharp/whats-new/csharp-14)
- [Breaking changes in .NET 10](https://learn.microsoft.com/en-us/dotnet/core/compatibility/10.0)
- [ASP.NET Core 10](https://learn.microsoft.com/en-us/aspnet/core/release-notes/aspnetcore-10.0)

### Documentation

- **XML Comments**: Required on all public APIs
- **Examples**: Provide code examples in XML docs when helpful
- **README Files**: Each satellite package has its own comprehensive README
- **Architecture Docs**: Maintain design decision records (ADRs) when applicable

### Git Workflow

- **No Force Push to main/master**: Never use `--force` on main branches
- **Commit Messages**: Clear, descriptive, in English
- **No AI Attribution**: Do NOT include any AI signatures, co-author tags, or Claude references in commits
  - ‚ùå Never add `Co-Authored-By: Claude...`
  - ‚ùå Never add `ü§ñ Generated with Claude Code`
  - ‚ùå Never add any reference to AI assistance in commit messages
- **Author**: All commits should appear as authored solely by the repository owner

### Build Environment Known Issues

> **Note**: After test consolidation (January 2026), the MSBuild CLR crash issue has been resolved.
> The full solution `Encina.slnx` now builds without issues. Solution filters (`.slnf`) are no longer needed.

#### SQLite DateTime Format Incompatibility

**Problem**: SQLite stores DateTime values as ISO 8601 text (e.g., `2026-01-05T12:30:00.0000000`), but SQLite's built-in `datetime('now')` function returns a different format (`2026-01-05 12:30:00`). This causes datetime comparisons in SQL queries to fail silently.

**Solution**: Never use `datetime('now')` in SQLite Dapper queries. Always use parameterized `@NowUtc` with `DateTime.UtcNow` from C#:

```csharp
// ‚ùå WRONG - datetime('now') format incompatible with ISO 8601
var sql = "SELECT * FROM Messages WHERE ProcessedAtUtc < datetime('now')";

// ‚úÖ CORRECT - Use parameterized DateTime from C#
var nowUtc = DateTime.UtcNow;
var sql = "SELECT * FROM Messages WHERE ProcessedAtUtc < @NowUtc";
await connection.QueryAsync<Message>(sql, new { NowUtc = nowUtc });
```

**Affected stores**: All `Encina.Dapper.Sqlite` stores use `TimeProvider` or `DateTime.UtcNow` for time-based queries.

**For tests**: When testing time-based behavior, use `TimeProvider` injection for deterministic time control.

### Spanish/English

- User communicates in Spanish
- Code, comments, documentation: **English only**
- Commit messages: English
- User-facing messages: Spanish when responding to user
- **Translation Rule**: If you encounter any Spanish comments in code while editing, translate them to English

## Quick Reference

### When to Use Each Pattern

- **Outbox**: Publishing domain events reliably (e-commerce order placed event)
- **Inbox**: Processing external messages idempotently (webhook handling, queue consumers)
- **Saga**: Coordinating distributed transactions (order fulfillment across services)
- **Scheduling**: Delayed execution of domain operations (send reminder in 24 hours)
- **Transactions**: Automatic commit/rollback based on ROP result

### Scheduling vs Hangfire/Quartz

- **Encina.Scheduling**: Domain messages (commands, queries, notifications)
- **Hangfire/Quartz**: Infrastructure jobs (cleanup tasks, reports, batch processing)
- **Complementary**: Both can coexist in the same application
- **Future**: Adapters to use Hangfire/Quartz as scheduling backends

### Common Errors to Avoid

1. ‚ùå Don't add `[Obsolete]` attributes for backward compatibility
2. ‚ùå Don't create migration helpers or compatibility layers
3. ‚ùå Don't use .NET 9 or older - only .NET 10
4. ‚ùå Don't name properties `Error` (use `ErrorMessage` to avoid CA1716)
5. ‚ùå Don't make patterns mandatory - everything is opt-in
6. ‚ùå Don't mix provider-specific code with abstractions
7. ‚ùå Don't compromise design for non-existent legacy users
8. ‚ùå Don't implement database features for only some providers - ALL 13 database providers required
9. ‚ùå Don't implement caching features for only some providers - ALL 8 caching providers required
10. ‚ùå Don't implement messaging features for only some transports - consider ALL applicable transports
11. ‚ùå Don't implement cloud features without considering AWS/Azure/GCP triangle
12. ‚ùå Don't skip test types without creating a justification `.md` file
13. ‚ùå Don't leave test coverage below 85%
14. ‚ùå Don't use `BenchmarkRunner.Run<T>()` - use `BenchmarkSwitcher.FromAssembly().Run(args, config)`
15. ‚ùå Don't return `IQueryable<T>` from benchmark methods - always materialize with `.ToList()`

> **Provider Rules Summary**: See [Specialized Provider Categories](#specialized-provider-categories-beyond-the-13-database-providers) for detailed rules on each provider category.

### Remember
>
> "We're in Pre-1.0. Choose the best solution, not the compatible one."

## Issue Tracking & Project Documentation

This project uses a structured approach to track issues, changes, and history.

### GitHub Issues (Primary Issue Tracker)

**All bugs, features, and technical debt MUST be tracked via GitHub Issues.**

Location: <https://github.com/dlrivada/Encina/issues>

#### Issue Templates

Use the appropriate template when creating issues:

| Template | Prefix | Use Case | Default Label |
|----------|--------|----------|---------------|
| `bug_report.md` | `[BUG]` | Bugs or unexpected behavior in Encina code | `bug` |
| `feature_request.md` | `[FEATURE]` | New features or enhancements | `enhancement` |
| `technical_debt.md` | `[DEBT]` | Code quality issues, missing implementations, optimization | `technical-debt` |
| `test_implementation.md` | `[TEST]` | New tests, benchmarks, load tests, coverage gaps | `area-testing` |
| `architecture_spike.md` | `[SPIKE]` | Technical investigations, evaluations, architecture decisions | `investigation` |
| `epic.md` | `[EPIC]` | Group related work spanning multiple issues | `epic` |
| `refactoring.md` | `[REFACTOR]` | Code restructuring without behavior change | `enhancement` |
| `infrastructure.md` | `[INFRA]` | CI/CD, Docker, build system, developer tooling | `area-ci-cd` |

**Choosing the right template:**

| Scenario | Template |
|----------|----------|
| Code throws wrong exception | `[BUG]` |
| Add GDPR compliance module | `[FEATURE]` |
| Coverage below 85%, need more tests | `[TEST]` |
| Implement NBomber load tests for Kafka | `[TEST]` |
| Code works but is messy / duplicated | `[DEBT]` |
| Evaluate Aspire vs Testcontainers | `[SPIKE]` |
| Apply Orchestrator pattern to 3 modules | `[REFACTOR]` |
| CI workflow takes 2+ hours | `[INFRA]` |
| 10-issue initiative with phases | `[EPIC]` |
| Failing tests due to code bug | `[BUG]` (not `[TEST]`) |
| Missing tests for existing code | `[TEST]` (not `[DEBT]`) |

**Prefix normalization rules:**

- ‚ùå `[TECH-DEBT]` ‚Üí use `[DEBT]`
- ‚ùå `[TESTING]` ‚Üí use `[TEST]`
- ‚ùå `[ARCHITECTURE]` / `[DECISION]` / `[REVIEW]` ‚Üí use `[SPIKE]`
- ‚ùå `[Phase N]` ‚Üí don't use phase prefixes; use milestones instead

#### When to Create Issues

Nunca dejaremos sin resolver o anotar un problema identificado. Lo normal ser√° resolver en el momento, pero si resolverlo significa cambiar significativamente el limitado contexto, lo que haremos es anotarlo, para no olvidarlo y resolverlo en otro momento con otro contexto. Para anotarlo, abriremos una Issue con el problema encontrado, y continuaremos con nuestra tarea. Al final en el resumen informaremos de las issues abiertas.

- **Bugs found during development** ‚Üí Create immediately with `[BUG]` prefix
- **Technical debt discovered** ‚Üí Create with `[DEBT]` prefix (don't fix inline if it risks derailing current work)
- **Feature ideas** ‚Üí Create with `[FEATURE]` prefix for later discussion
- **Missing tests / coverage gaps** ‚Üí Create with `[TEST]` prefix and link to specific packages
- **Failing tests due to code bug** ‚Üí Create with `[BUG]` (the bug is in the code, not the tests)
- **Architecture investigations** ‚Üí Create with `[SPIKE]` prefix with time-boxed scope
- **CI/CD or build issues** ‚Üí Create with `[INFRA]` prefix
- **Large multi-issue initiatives** ‚Üí Create with `[EPIC]` prefix, then create child issues
- **Code restructuring** ‚Üí Create with `[REFACTOR]` prefix (no behavior change)

#### Workflow

1. **Find issue** ‚Üí Create GitHub Issue using appropriate template
2. **Start work** ‚Üí Assign issue to yourself, move to "In Progress"
3. **Complete work** ‚Üí Reference issue in commit (`Fixes #123`) or PR
4. **Issue auto-closes** when PR is merged

### Project Documentation Files

| File | Purpose |
|------|---------|
| `CHANGELOG.md` | Track released changes (follows Keep a Changelog format) |
| `ROADMAP.md` | High-level roadmap and planned features |
| `docs/releases/vX.Y.Z/` | Version-based release documentation |
| `docs/architecture/adr/*.md` | Architecture Decision Records |
| `docs/roadmap-documentacion.md` | Documentation-specific roadmap |

### When Updating Documentation

- **After completing a feature** ‚Üí Update `CHANGELOG.md` (Unreleased section)
- **After major implementation phase** ‚Üí Update `docs/releases/vX.Y.Z/README.md`
- **After architectural decisions** ‚Üí Create ADR in `docs/architecture/adr/`
- **After releasing** ‚Üí Move Unreleased to version section in `CHANGELOG.md`

### DO NOT Track Issues Here

This CLAUDE.md file is for **development guidelines**, not issue tracking.

- ‚ùå Don't add "Known Issues" sections here
- ‚ùå Don't track bugs or technical debt in this file
- ‚úÖ Use GitHub Issues for all tracking
- ‚úÖ Reference issue numbers in commits and PRs

## CodeRabbit Integration

This project uses [CodeRabbit](https://coderabbit.ai) for AI-powered code reviews and issue management. Configuration is in `.coderabbit.yaml`.

### CodeRabbit Features

#### 1. Pull Request Reviews

CodeRabbit automatically reviews all PRs with:

- Code quality analysis
- Security vulnerability detection
- Best practices suggestions
- .NET 10 / C# 14 specific guidance

**Interacting with CodeRabbit in PRs:**

| Command | Effect |
|---------|--------|
| `@coderabbitai review` | Request a new review |
| `@coderabbitai resolve` | Mark all comments as resolved |
| `@coderabbitai plan` | Generate implementation plan |
| `@coderabbitai help` | Show available commands |

#### 2. Issue Enrichment (Automatic)

When you **create or edit** an issue, CodeRabbit automatically:

- **Detects duplicates** - Finds existing issues that may be duplicates
- **Finds related issues** - Links similar issues for context
- **Finds related PRs** - Shows PRs that addressed similar problems
- **Suggests assignees** - Recommends team members based on expertise
- **Auto-labels** - Categorizes issues with appropriate labels

> **Note**: CodeRabbit only triggers on new/edited issues, not existing ones. To enrich an existing issue, make a minor edit to trigger re-analysis.

#### 3. Linked Issue Validation

When a PR references an issue (e.g., `Fixes #123`), CodeRabbit:

1. Analyzes the issue title and description
2. Examines the PR changes
3. Validates if changes meet the requirements
4. Provides assessment: ‚úÖ Addressed, ‚ùå Not addressed, or ‚ùì Unclear

**Best practices for linked issue validation:**

- Write clear, technical issue titles
- Include specific acceptance criteria in descriptions
- Use consistent terminology between issues and PRs
- Reference issues with `Fixes #N` or `Closes #N` in PR description

#### 4. Plan Mode (Implementation Planning)

CodeRabbit can generate detailed implementation plans from issues:

**How to trigger:**

- Check the "Create Plan" checkbox in the enrichment comment
- Or comment `@coderabbitai plan` on the issue

**What it generates:**

- Step-by-step implementation plan
- File-specific guidance on what to change
- Code examples from the codebase
- Testing recommendations

**Use with Claude Code:**
The generated plan can be copied and used as context for Claude Code sessions. This is especially useful for complex features.

#### 5. Configuration (`.coderabbit.yaml`)

Key settings for this project:

```yaml
language: es-ES  # Spanish summaries
reviews:
  high_level_summary: true
  path_instructions:
    - path: "src/**/*.cs"
      instructions: ".NET 10, C# 14, zero warnings..."
  path_filters:
    - "!docs/INVENTORY.md"  # Excluded from review
```

**Auto-planning by label:**

```yaml
issue_enrichment:
  planning:
    auto_planning:
      enabled: true
      labels:
        - "plan-me"      # Issues with this label get auto-planned
        - "!no-plan"     # Issues with this label are excluded
```

### Workflow: Issues + CodeRabbit + Claude Code

1. **Create Issue** ‚Üí CodeRabbit enriches with related issues/PRs
2. **Request Plan** ‚Üí `@coderabbitai plan` generates implementation steps
3. **Copy Plan** ‚Üí Use as context in Claude Code session
4. **Create PR** ‚Üí Reference issue with `Fixes #N`
5. **CodeRabbit Reviews** ‚Üí Validates PR addresses issue requirements
6. **Iterate** ‚Üí Address CodeRabbit comments
7. **Merge** ‚Üí Issue auto-closes

### Tips for Effective CodeRabbit Usage

1. **Write detailed issue descriptions** - CodeRabbit uses titles and descriptions (not comments) for analysis
2. **Use conventional commits** - Helps CodeRabbit understand change context
3. **Reference issues in PRs** - Enables linked issue validation
4. **Review the enrichment** - Check related issues/PRs for context before starting work
5. **Leverage Plan Mode** - For complex features, let CodeRabbit analyze the codebase first

### Requesting CodeRabbit Analysis on Existing Issues

CodeRabbit only enriches issues automatically when they are **created or edited**. For existing issues without CodeRabbit analysis:

1. **Comment to trigger analysis**: Add a comment like `@coderabbitai please review this issue`
2. **Wait for response**: CodeRabbit will analyze and reply with enrichment (duplicates, related issues, suggestions)
3. **Request a plan**: Use `@coderabbitai plan` to generate implementation steps

**Standard workflow when reviewing an issue without CodeRabbit comments:**

```
@coderabbitai please analyze this issue and suggest related issues/PRs
```

This practice ensures we get CodeRabbit's insights on all issues we work on, not just newly created ones.
